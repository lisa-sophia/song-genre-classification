{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a1c870-410b-43ac-bf9a-9dd48006ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7764d34-11d7-49d5-b2dc-b7a928d2a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_test, y_test, labels=None, label_encoder=None):\n",
    "    labels = list(model.classes_)\n",
    "    pred = model.predict(X_test) \n",
    "    if type(model[1]) == XGBClassifier:\n",
    "        pred = label_encoder.inverse_transform(pred)\n",
    "        labels = label_encoder.inverse_transform(labels)\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    # normalize : {'true', 'pred', 'all'}, default=None\n",
    "    # Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. \n",
    "    # If None, confusion matrix will not be normalized.\n",
    "    cm = confusion_matrix(y_test, pred, normalize=None) \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(ax=ax)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    #print(classification_report(y_test, pred))\n",
    "    print(\"Accuracy  = \" + str(accuracy_score(y_true=y_test, y_pred=pred)))\n",
    "    print(\"F1 score  = \" + str(f1_score(y_true=y_test, y_pred=pred, average='weighted')))\n",
    "    print(\"Precision = \" + str(precision_score(y_true=y_test, y_pred=pred, average='weighted')))\n",
    "    print(\"Recall    = \" + str(recall_score(y_true=y_test, y_pred=pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99076d4d-9ace-48f1-9818-fbfbf00d66a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4674/1781768872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraindf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train_data.csv'"
     ]
    }
   ],
   "source": [
    "traindf = pd.read_csv('../data/train_data.csv')\n",
    "traindf['tokenized'] = traindf['tokenized'].apply(literal_eval)\n",
    "traindf['lemmatized'] = traindf['lemmatized'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba014fb-c27a-4505-babf-10383228734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('../data/test_data.csv')\n",
    "testdf['tokenized'] = testdf['tokenized'].apply(literal_eval)\n",
    "testdf['lemmatized'] = testdf['lemmatized'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45c14a-a791-488d-8eec-f616c1cc0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345\n",
    "LABELS = traindf.genre.unique().tolist()\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d52381-d2ab-4202-87ad-ac2c497028c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.1)\n",
    "traindf['genre'].value_counts().plot(kind='bar', rot=0, figsize=(8,5))\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count of songs\")\n",
    "plt.title(\"Counts of songs by genre - training data\", y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caeb2ed-c2fa-4fc8-86a1-c6ec4a27f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.1)\n",
    "testdf['genre'].value_counts().plot(kind='bar', rot=0, figsize=(8,5))\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count of songs\")\n",
    "plt.title(\"Counts of songs by genre - holdout set\", y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d241c36-c77f-4212-8f13-38a6fb3d8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = traindf['lemmatized']\n",
    "y_train = traindf['genre']#.astype(\"category\")\n",
    "X_test = testdf['lemmatized']\n",
    "y_test = testdf['genre']#.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6b63f-52bb-4f48-952e-2224e3e65644",
   "metadata": {},
   "source": [
    "## Try out some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eaacdf-70f6-4a45-b50c-35ee90427835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda479f6-3a14-4ddc-8a0d-556cd7d540bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels for xgboost\n",
    "label_enc = LabelEncoder()\n",
    "label_enc = label_enc.fit(y_train)\n",
    "y_train_enc = label_enc.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598495eb-fad3-4489-b64e-7a073b55b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5344b-038f-4104-839d-76770779248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline & Gridsearch setup\n",
    "# MultinomialBayes pipeline setup\n",
    "mb_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer=dummy_fun, preprocessor=dummy_fun)),\n",
    "    ('mb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit\n",
    "mb_pipe.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classifier(mb_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61716d-196d-45ff-840b-b99566f8e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomforest pipeline setup\n",
    "rf_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer=dummy_fun, preprocessor=dummy_fun)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classifier(rf_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6ed52-0e1c-4ca1-903c-a9dca238e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM pipeline setup\n",
    "svm_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer=dummy_fun, preprocessor=dummy_fun)),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Fit\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classifier(svm_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18625e7-d3c7-4d62-9175-318737e9747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost pipeline setup\n",
    "xgb_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer=dummy_fun, preprocessor=dummy_fun)),\n",
    "    ('xgb', XGBClassifier(objective='multi:softprob'))\n",
    "    #('xgb', XGBClassifier(random_state=42, seed=2, colsample_bytree=0.6, subsample=0.7))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "xgb_pipe.fit(X_train, y_train_enc)\n",
    "\n",
    "evaluate_classifier(xgb_pipe, X_test, y_test, label_encoder=label_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e034e-2b7d-474f-a046-81087b85170b",
   "metadata": {},
   "source": [
    "# Gridsearch to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c50ac6-dd00-4db4-8d5f-eeaaed20e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = 'accuracy'\n",
    "# SCORING = 'balanced_accuracy'\n",
    "# SCORING = 'f1_weighted'\n",
    "# SCORING = 'roc_auc_ovo_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394a3d1-ac4a-49df-a56c-c11f339cdf63",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43e2d5-c0bc-48f9-9ff1-39bc5c0d4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting params for MultinomialBayes gridsearch\n",
    "mb_params = {\n",
    "    'vec__tokenizer':[dummy_fun],\n",
    "    'vec__preprocessor':[dummy_fun],\n",
    "    'vec__max_df':[0.8],\n",
    "    'mb__alpha': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "# Setting up GridSearch for MultinomialBayes\n",
    "mb_gs = GridSearchCV(mb_pipe, param_grid=mb_params, cv=5, scoring=SCORING)\n",
    "# Fitting MultiBayes GS\n",
    "mb_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV score = %0.3f with the following parameters:\" % mb_gs.best_score_)\n",
    "print(mb_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874b001-10f8-44d2-bfe1-1615ca4e154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(mb_gs.best_estimator_, X_test, y_test, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea242d1-cb24-4601-bb6e-6ac0f18ea98e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a10a9e-40fd-4b79-b6cd-f3c1eba2a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up randomforest params\n",
    "rf_params = {\n",
    "    'vec__tokenizer':[dummy_fun],\n",
    "    'vec__preprocessor':[dummy_fun],\n",
    "    'vec__max_df':[0.8],\n",
    "    'rf__n_estimators': [50, 100, 500, 1000],\n",
    "    'rf__max_depth': [3, 10, None],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Setting up GridSearch for Randomforest\n",
    "rf_gs = GridSearchCV(rf_pipe, param_grid=rf_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting Randomforest CV GS\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest CV score = %0.3f with the following parameters:\" % rf_gs.best_score_)\n",
    "print(rf_gs.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(rf_gs.best_estimator_, X_test, y_test, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ddb15-4fdf-4799-8508-ee6516d86beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Randomforest\n",
    "rf_gs2 = GridSearchCV(rf_pipe, param_grid=rf_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting Randomforest CV GS\n",
    "rf_gs2.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest CV score = %0.3f with the following parameters:\" % rf_gs2.best_score_)\n",
    "print(rf_gs2.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(rf_gs2.best_estimator_, X_test, y_test, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468dcfe-4407-4634-bd04-5de7ab6ac124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Randomforest\n",
    "rf_gs3 = GridSearchCV(rf_pipe, param_grid=rf_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting Randomforest CV GS\n",
    "rf_gs3.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest CV score = %0.3f with the following parameters:\" % rf_gs3.best_score_)\n",
    "print(rf_gs3.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(rf_gs3.best_estimator_, X_test, y_test, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca890b3b-52cf-41b8-a62e-f6f48a50ce5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c0b2a-a094-4b01-9dd7-7a4cf76b4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting params for MultinomialBayes gridsearch\n",
    "svm_params = {\n",
    "    'vec__tokenizer':[dummy_fun],\n",
    "    'vec__preprocessor':[dummy_fun],\n",
    "    'vec__max_df':[0.8],\n",
    "    'svm__C': [0.1, 1, 10, 100, 1000],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'svm__gamma': ['auto', 'scale', 1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# Setting up GridSearch for MultinomialBayes\n",
    "svm_gs = GridSearchCV(svm_pipe, param_grid=svm_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting MultiBayes GS\n",
    "svm_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV score = %0.3f with the following parameters:\" % svm_gs.best_score_)\n",
    "print(svm_gs.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(svm_gs.best_estimator_, X_test, y_test, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7f331-1a26-466d-88fb-83fd59c38d98",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647fc2c-dfbb-4e36-a59f-e715004d8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting params for XGBoost gridsearch\n",
    "xgb_params = {\n",
    "    'vec__tokenizer':[dummy_fun],\n",
    "    'vec__preprocessor':[dummy_fun],\n",
    "    'vec__max_df':[0.8],\n",
    "    'xgb__max_depth': [3, 6, 10],\n",
    "    'xgb__n_estimators': [50, 100, 200, 500],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__random_state': [123],\n",
    "    'xgb__seed': [123],\n",
    "}\n",
    "\n",
    "# Setting up GridSearch for XGBoost\n",
    "xgb_gs = GridSearchCV(xgb_pipe, param_grid=xgb_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting MultiBayes GS\n",
    "xgb_gs.fit(X_train, y_train_enc)\n",
    "\n",
    "print(\"Best CV score = %0.3f with the following parameters:\" % xgb_gs.best_score_)\n",
    "print(xgb_gs.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(xgb_gs.best_estimator_, X_test, y_test, LABELS, label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d169b9-ac9f-47d5-b15e-f4f092ad53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting params for XGBoost gridsearch\n",
    "xgb_params = {\n",
    "    'vec__tokenizer':[dummy_fun],\n",
    "    'vec__preprocessor':[dummy_fun],\n",
    "    'vec__max_df':[0.8],\n",
    "    'xgb__max_depth': [3, 6, 10],\n",
    "    'xgb__n_estimators': [50, 100, 200, 500],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__random_state': [456],\n",
    "    'xgb__seed': [456],\n",
    "}\n",
    "\n",
    "# Setting up GridSearch for XGBoost\n",
    "xgb_gs = GridSearchCV(xgb_pipe, param_grid=xgb_params, cv=5, verbose=1, n_jobs=-1, scoring=SCORING)\n",
    "# Fitting MultiBayes GS\n",
    "xgb_gs.fit(X_train, y_train_enc)\n",
    "\n",
    "print(\"Best CV score = %0.3f with the following parameters:\" % xgb_gs.best_score_)\n",
    "print(xgb_gs.best_params_)\n",
    "print(\"\")\n",
    "evaluate_classifier(xgb_gs.best_estimator_, X_test, y_test, LABELS, label_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b1c3b-447d-4186-9bfe-8440afaaafa8",
   "metadata": {},
   "source": [
    "# Train optimal pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f48533-20d4-4db0-b8b8-1d41529b42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal pipeline setup\n",
    "opt_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(\n",
    "        tokenizer=dummy_fun, \n",
    "        preprocessor=dummy_fun,\n",
    "        max_df=0.8,\n",
    "    )),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        n_estimators=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "opt_pipe.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classifier(opt_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff3e2f-2bf7-4ec1-94fe-fa1eb5f927ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal pipeline setup\n",
    "opt_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(\n",
    "        tokenizer=dummy_fun, \n",
    "        preprocessor=dummy_fun,\n",
    "        max_df=0.8,\n",
    "    )),\n",
    "    ('xgb', XGBClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        seed=RANDOM_STATE,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "opt_pipe.fit(X_train, y_train_enc)\n",
    "\n",
    "evaluate_classifier(opt_pipe, X_test, y_test, label_encoder=label_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
